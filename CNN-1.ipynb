{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============== DOWNLOAD THE IMAGES ============\n",
        "import os\n",
        "import requests\n",
        "\n",
        "classes = ['cat', 'dog', 'tree', 'clock']\n",
        "base_url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap\"\n",
        "save_dir = \"/content/quickdraw_npy\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for cls in classes:\n",
        "    url = f\"{base_url}/{cls}.npy\"\n",
        "    save_path = f\"{save_dir}/{cls}.npy\"\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "        print(f\"‚¨áÔ∏è Downloading {cls}.npy...\")\n",
        "        r = requests.get(url)\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "    else:\n",
        "        print(f\"‚úîÔ∏è {cls}.npy already exists.\")\n",
        "print(\"‚úÖ All downloads done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qElZu3fF8Yb",
        "outputId": "e63e2b12-c198-41be-f354-91ee98f72ac8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Downloading cat.npy...\n",
            "‚¨áÔ∏è Downloading dog.npy...\n",
            "‚¨áÔ∏è Downloading tree.npy...\n",
            "‚¨áÔ∏è Downloading clock.npy...\n",
            "‚úÖ All downloads done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Files in /content/quickdraw_npy:\")\n",
        "print(os.listdir(\"/content/quickdraw_npy\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crZGq1kOFvGj",
        "outputId": "20ba86f4-3fcd-495a-ea9f-6f8948dace5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in /content/quickdraw_npy:\n",
            "['dog.npy', 'tree.npy', 'cat.npy', 'clock.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKES COMBINED DATASET WITH 1000 IMAGES EACH FROM ALL 4 CXATEGORIES AND SPLIT THEM INTO TRAIN TEST DATASETS\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Classes you want to include\n",
        "classes = ['cat', 'dog', 'tree', 'clock']\n",
        "class_labels = {cls: i for i, cls in enumerate(classes)}\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Load 1000 samples per class and label\n",
        "for cls in classes:\n",
        "    data = np.load(f\"/content/quickdraw_npy/{cls}.npy\")\n",
        "    X.append(data[:1000])  # take only first 1000 images\n",
        "    y.append(np.full(1000, class_labels[cls]))  # e.g., 0 for cat, 1 for dog\n",
        "\n",
        "# Stack everything together\n",
        "X = np.concatenate(X, axis=0).reshape(-1, 28, 28, 1) / 255.0  # normalize and reshape\n",
        "y = np.concatenate(y, axis=0)\n",
        "\n",
        "# Shuffle the data\n",
        "X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "'''Perfect, Tekendra! That means you've successfully:\n",
        "\n",
        "üß† Created a mixed dataset from 4 classes (cat, dog, tree, clock)\n",
        "\n",
        "üéØ Preprocessed it correctly (normalized + reshaped)\n",
        "\n",
        "üé≤ Shuffled and split into train/test sets'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "I2f_kEiz65l3",
        "outputId": "7d32bed8-77f0-4e09-9da0-d02e7c4a005d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3200, 28, 28, 1)\n",
            "y_train shape: (3200,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Perfect, Tekendra! That means you've successfully:\\n\\nüß† Created a mixed dataset from 4 classes (cat, dog, tree, clock)\\n\\nüéØ Preprocessed it correctly (normalized + reshaped)\\n\\nüé≤ Shuffled and split into train/test sets\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VIEW SOME RANDOM IMAGES FROM THE DATASET\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Suppose you have your dataset X (N, 28, 28, 1) and labels y (N,)\n",
        "# Let's visualize 5 random images:\n",
        "\n",
        "def show_random_images(X, y, class_names, num=5):\n",
        "    indices = np.random.choice(len(X), num, replace=False)\n",
        "    plt.figure(figsize=(10, 2))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img = X[idx].reshape(28, 28)  # remove channel dimension\n",
        "        label = class_names[y[idx]]\n",
        "\n",
        "        plt.subplot(1, num, i + 1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Your class names map, for example\n",
        "class_names = ['cat', 'dog', 'tree', 'clock']\n",
        "\n",
        "# Call the function with your training data\n",
        "show_random_images(X_train, y_train, class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "StMk92hv7P_B",
        "outputId": "8a05c41c-85cb-4a88-c7a1-5c91fdcefd64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABA ARU KAM VAYO NOW STARTS THE REAL NEURAL NETWORK MAKING\n",
        "# YO STEPS HARU GARNE:\n",
        "'''\n",
        "1. image line (28*28)\n",
        "2. use n filters of (3*3)  no of wts = 3*3* no of filters + bias= no of filters\n",
        "3. we get feature map  (26*26) ko\n",
        "4. pass feature map into relu (negative value 0 hunxa positive same hunxa)  (26*26)\n",
        "5. max pooling use garne (2*2)ko and stride=2     (feature map sano hunxa i.e. half) .......output of (13* 13)\n",
        "6. flattern i.e convert 2D images to 1D tensor   (13, 13) ko 1D tensor for single image\n",
        "7. Pass that flaterned tensor into the neural networks.\n",
        "8. output layer with perceptron in this layer= no of category\n",
        "USE SOFTMAX FOR CLASSIFICATION i.e pass the output from the output layer into the softmax."
      ],
      "metadata": {
        "id": "x7AhAkp-_4r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# ===== ReLU =====\n",
        "\n",
        "# ReLU = Rectified Linear Unit. It replaces all negative values with 0, and keeps positive values unchanged. üìà Used to add non-linearity to the model.\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "\n",
        "# ===================== MAX POOLING 2x2 with stride 2 ===================================\n",
        "\n",
        "#Takes a 2x2 region and picks the maximum value (downsampling).\n",
        "#üî∏ Reduces size of image by half ‚Üí e.g. from (26x26) ‚Üí (13x13)\n",
        "\n",
        "def max_pooling(feature_map):          # feature map is the 2D array output got from filter(i.e. RELU bata)\n",
        "    h, w = feature_map.shape           # shape of the feature map i.e. h=HEIGHT   w= WIDTH\n",
        "    out = np.zeros((h // 2, w // 2))   #Create an empty array to store the pooled result i.e. yaha half of the inputs: (26, 26)=> (13, 13)\n",
        "\n",
        "\n",
        "    for i in range(0, h, 2):                 # Loop through the feature map with steps of 2 (stride = 2)\n",
        "        for j in range(0, w, 2)              # i moves down (rows), j moves right (columns)   So each iteration covers one 2√ó2 block like this:\n",
        "            out[i//2, j//2] = np.max(feature_map[i:i+2, j:j+2])          # This line grabs a 2√ó2 region starting at (i, j)\n",
        "                                                                          # Then applies np.max() to that 2√ó2 block ‚Üí selects maximum value and Places that max value in the output array at position (i//2, j//2)\n",
        "    return out\n",
        "\n",
        "# Why i//2, j//2?   ==== Because we are reducing size by half, so every (i,j) in input becomes (i//2, j//2) in output.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ================== SOFTMAX ===========================\n",
        "\n",
        "#Converts raw scores into probabilities that add up to 1\n",
        "#üéØ Used in the output layer to represent confidence for each class (e.g. 20% cat, 80% dog)\n",
        "#  The softmax function takes a vector of raw scores (called logits) from the output layer and turns them into probabilities that: Are between 0 and 1  and Sum of probabilities of all category is 1\n",
        "\n",
        "def softmax(x):                  # x is a 1D NumPy array ‚Äî the output scores from the final layer of the network (before activation)\n",
        "    exp_x = np.exp(x - np.max(x))\n",
        "    return exp_x / np.sum(exp_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===== Convolution Layer (Single filter)  output= feature map =====\n",
        "\n",
        "# Applies a filter (kernel) to the image using a sliding window.\n",
        "# At each position, it multiplies region values and filter weights, adds bias, and stores the result.\n",
        "# üß† This is how CNN \"sees\" edges, curves, shapes, etc.\n",
        "\n",
        "def convolve(image, filt, bias):\n",
        "    h, w = image.shape\n",
        "    fh, fw = filt.shape    # filter ko height ra width\n",
        "    out_h = h - fh + 1\n",
        "    out_w = w - fw + 1\n",
        "                       ''' (28, 28) => (26, 26)\n",
        "                       ''' # ailesamma output ko height ra width kati hunxa nikalyo and stored in out_h and out_w\n",
        "                           # We‚Äôre using valid convolution (no padding), so the output size shrinks.\n",
        "\n",
        "    out = np.zeros((out_h, out_w))         # Prepares an empty 2D array for the feature map.\n",
        "\n",
        "    # Initially filled with zeros ‚Äî we will fill it with convolution results from the following lope\n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            region = image[i:i+fh, j:j+fw]\n",
        "                        '''Extracts a 3√ó3 block from the image at position (i, j)\n",
        "                        For example, if i=5, j=7, this will take the block:\n",
        "                        image[5:8, 7:10]'''\n",
        "\n",
        "            out[i, j] = np.sum(region * filt) + bias\n",
        "                        ''' Performs element-wise multiplication between region and filter\n",
        "                        Then sums all the products\n",
        "                        Adds the bias\n",
        "                        Stores the result in the output feature map at position (i, j)'''\n",
        "    return out\n",
        "    #  After the loop finishes, out holds the entire convolved image (feature map).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===== Fully Connected Layer =====\n",
        "\n",
        "# Takes a flattened vector (from image) and connects to output neurons.\n",
        "#  This layer gives raw scores for each class.\n",
        "\n",
        "def fully_connected(flat_input, weights, bias):\n",
        "    return np.dot(flat_input, weights) + bias\n",
        "              ''' üîö Output:\n",
        "              Returns a vector of raw scores (logits) ‚Äî one for each class.\n",
        "              You pass this into softmax to convert them into probabilities '''\n"
      ],
      "metadata": {
        "id": "rKS1Gj3A_LUD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "28x28 image\n",
        "\n",
        "\n",
        "   ‚Üì\n",
        "\n",
        "Convolution (3x3)\n",
        "\n",
        "   ‚Üì\n",
        "\n",
        "ReLU\n",
        "\n",
        "   ‚Üì\n",
        "\n",
        "Max Pooling (2x2, stride 2)\n",
        "\n",
        "   ‚Üì\n",
        "\n",
        "Flatten (13x13xN)\n",
        "\n",
        "   ‚Üì\n",
        "\n",
        "Fully connected layer (output: 4 values)\n",
        "\n",
        "   ‚Üì\n",
        "   \n",
        "Softmax ‚Üí [p_cat, p_dog, p_tree, p_clock]\n"
      ],
      "metadata": {
        "id": "InZNmN6vIyj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YO forwad_pass() FUNCTION LE CONVOLUTION LAYER MA HUNE SABAI KAM LAI HANDLE GARXA i.e.   \n",
        "1. CONVOLVE GARXA\n",
        "2. RELU MA PATHAUXA   \n",
        "3. MAX POOLING   \n",
        "4. CREATES ARRAY OF ALL THE FEATURE MAPS FOR THAT IMAGE    \n",
        "5. FLATTERNS AND MAKES READY TO PASS INTO FULLY CONNECTED LAYERS."
      ],
      "metadata": {
        "id": "Q9LeF9ttnCqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def forward_pass(image, conv_filters, conv_biases):\n",
        "    feature_maps = []       # Initialize an empty list to store the output of each filter (i.e., each feature map).   After applying filters, each filter produces a 2D map ‚Üí we collect all of them here.\n",
        "\n",
        "\n",
        "                        ''' Loop through all filters and their corresponding biases.\n",
        "                        conv_filters: list of 2D filters (e.g., 3√ó3)\n",
        "                        conv_biases: list of scalar bias values (1 per filter)\n",
        "                        zip() pairs them'''\n",
        "    for f, b in zip(conv_filters, conv_biases):\n",
        "\n",
        "        fm = convolve(image, f, b)    # Apply your convolve() function to the image using the current filter f and bias b. Output is a 2D feature map (e.g., 26√ó26\n",
        "\n",
        "        fm = relu(fm)    # Pass the feature map through the ReLU function.\n",
        "\n",
        "        fm = max_pooling(fm)      # Applies 2√ó2 max pooling with stride 2  and Reduces spatial dimensions (from 26√ó26 to 13√ó13)\n",
        "\n",
        "        feature_maps.append(fm)    # Add the current feature map to the list of feature maps.  we will have multiple 13√ó13 maps each from different filters\n",
        "\n",
        "    conv_output = np.array(feature_maps) # Convert the list of feature maps into a single NumPy array  Final shape: (num_filters, height, width) ‚Üí e.g. (8, 13, 13)\n",
        "                                        # This is the 3D output volume from the convolutional layers\n",
        "\n",
        "    flat = conv_output.reshape(-1)         # Flattens the 3D output into a 1D vector\n",
        "    return flat\n",
        "                    ''' Returns the flattened vector ‚Äî this is the final output of the convolutional stack (before classification).\n",
        "                    Next, this gets passed into fully_connected() ‚Üí softmax() ‚Üí prediction.'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ======== LOSS FUNCTION =================================\n",
        "\n",
        "# This function calculates the cross-entropy loss for a single prediction. It measures how far off your model‚Äôs predicted probability (preds) is from the correct label.\n",
        "# preds: A 1D array of predicted probabilities (after softmax), e.g. [0.1, 0.3, 0.2, 0.4]\n",
        "# label:  The true class index (e.g. 2 if it‚Äôs class #2)\n",
        "\n",
        "def cross_entropy(preds, label):\n",
        "    epsilon = 1e-10\n",
        "    return -np.log(preds[label] + epsilon)      # Loss= ‚àílog(predicted probability of the correct class)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ========= CALCULATE DERIVATIVE dL/dz =========================\n",
        "\n",
        "# This function calculates the gradient of the loss (cross-entropy) with respect to the logits (z) that were passed into the softmax.\n",
        "\n",
        "def softmax_grad(preds, label):\n",
        "    grad = preds.copy()\n",
        "    grad[label] -= 1  # dL/dz = p - y (one-hot)\n",
        "    return grad\n"
      ],
      "metadata": {
        "id": "nI-tllA_EmNM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preds = softmax(z) (probabilities for each class)\n",
        "\n",
        "y is the true label (not one-hot, just an index)\n",
        "\n",
        "Then:\n",
        "\n",
        "‚àÇ\n",
        "Loss/‚àÇ\n",
        "ùëß\n",
        "ùëñ\n",
        "=\n",
        "softmax\n",
        "(\n",
        "ùëß\n",
        ")\n",
        "ùëñ\n",
        "‚àí\n",
        "ùë¶\n",
        "ùëñ"
      ],
      "metadata": {
        "id": "iz0ta6_bjEwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Data ====\n",
        "classes = ['cat', 'dog', 'tree', 'clock']\n",
        "n_classes = len(classes)\n",
        "n_filters = 8               # Each image will be processed through 8 different 3√ó3 filters.\n",
        "filter_size = 3\n",
        "flattened_size = 13 * 13 * n_filters     # flattened_size = 1352 ‚Üí After convolution and pooling, each image becomes (8, 13, 13) ‚Üí flatten to 1352-length vector for FC layer.\n",
        "\n",
        "# ============ Random INITILIZATION ============\n",
        "np.random.seed(0)\n",
        "conv_filters = [np.random.randn(3, 3) * 0.1 for _ in range(n_filters)]\n",
        "conv_biases = [0.0 for _ in range(n_filters)]\n",
        "fc_weights = np.random.randn(flattened_size, n_classes) * 0.1  # no of weights = flatterened size(i.e. 13*13 * 8 (no of filters)) * 4 (i.e. no of output classes)\n",
        "fc_biases = np.zeros(n_classes)     # no of fully connected layers = no of classes and initialize all the biases to 0.\n",
        "\n",
        "# ==== Training ====\n",
        "lr = 0.01   #Learning Rate\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0     # initialize total loss\n",
        "    correct = 0     # initialize the no of correctly classified images\n",
        "    X_train, y_train = shuffle(X_train, y_train)  # suffles the images for better working\n",
        "\n",
        "    for i in range(len(X_train)):     # let(X_train)= no of images in the X_train. ===> This is to lope through all the training images\n",
        "        img = X_train[i].reshape(28, 28)\n",
        "        label = y_train[i]            # the label i.e. actual type of that specific images i.e. expected/correct output\n",
        "\n",
        "        # Forward pass\n",
        "        flat = forward_pass(img, conv_filters, conv_biases)     # pass thhe image, the weights of all the filters and their biases into forward_pass() function which gives a flattened 1D array ready to pass into fully connected layer.\n",
        "\n",
        "        logits = fully_connected(flat, fc_weights, fc_biases)   # pass the output 1D array from forward_pass() to fully_connected() along with the weights and biases\n",
        "\n",
        "        probs = softmax(logits)    # pass the output from fully connected to softmax() to get the probabilities\n",
        "\n",
        "        # Loss\n",
        "        loss = cross_entropy(probs, label)  # calculates loss function based on the probabilities and the label\n",
        "        total_loss += loss\n",
        "        pred = np.argmax(probs)\n",
        "\n",
        "        if pred == label:\n",
        "            correct += 1   # if predicted output is same as label then increment the no of correctly predicted images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # =========BACKPROPAGATION  (only FC layer)==============================\n",
        "        grad_softmax = softmax_grad(probs, label)\n",
        "        grad_w = np.outer(flat, grad_softmax)\n",
        "        grad_b = grad_softmax\n",
        "\n",
        "        # ================= Gradient Descent update ================\n",
        "        fc_weights -= lr * grad_w\n",
        "        fc_biases -= lr * grad_b\n",
        "\n",
        "    acc = correct / len(X_train)\n",
        "    print(f\"üìö Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f} | Accuracy: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmXV644ZLjIj",
        "outputId": "695afa8c-37af-4079-a69a-89674ac944e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Epoch 1/5 | Loss: 1859.0719 | Accuracy: 77.72%\n",
            "üìö Epoch 2/5 | Loss: 1435.7172 | Accuracy: 82.41%\n",
            "üìö Epoch 3/5 | Loss: 1353.0172 | Accuracy: 83.59%\n",
            "üìö Epoch 4/5 | Loss: 1296.1134 | Accuracy: 84.47%\n",
            "üìö Epoch 5/5 | Loss: 1258.5482 | Accuracy: 84.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QguIJVrBvW5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}